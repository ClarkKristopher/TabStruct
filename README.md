# TabStruct: Measuring Structural Fidelity of Tabular Data

![TabStruct banner](https://s2.loli.net/2025/05/16/TZ1clpvNBDhi8AE.png)

## ðŸ“Œ Overview

**TabStruct** is an endâ€‘toâ€‘end benchmark for **tabular data generation, prediction, and evaluation**.  It ships with readyâ€‘toâ€‘use pipelines for

* generating highâ€‘quality synthetic tables,
* training predictive models, and
* analysing results with a rich suite of metricsâ€”especially those that quantify **structural fidelity**.

All components are designed to plugâ€‘andâ€‘play, so you can mix, match, and extend them to suit your own workflow.

```text
TabStruct/
â”œâ”€â”€ src/               # Core library
â”‚   â”œâ”€â”€ common/        # Shared utilities & configuration
â”‚   â”œâ”€â”€ experiment/    # Highâ€‘level experiment runners
â”‚   â”œâ”€â”€ generation/    # Syntheticâ€‘data pipeline
â”‚   â””â”€â”€ prediction/    # Downstreamâ€‘task pipeline
â”œâ”€â”€ private_repos/     # Patched thirdâ€‘party repos
â”œâ”€â”€ tests/             # Unit & integration tests
â”œâ”€â”€ environment.yml    # Conda environment spec
â”œâ”€â”€ pyproject.toml     # Project metadata & build config
â””â”€â”€ README.md          # You are here
```

## ðŸ“š Key Features

### Data generation

* Outâ€‘ofâ€‘theâ€‘box support for popular tabular generators: **SMOTE, TVAE, CTGAN, NFlow, TabDDPM, ARF**, and more.

### Evaluation metrics

* **Density estimation** â€“ How well does the synthetic data approximate the real distribution?
* **Privacy preservation** â€“ Does the generator leak sensitive records?
* **ML efficacy** â€“ How do models trained on synthetic data perform compared to real data?
* **Structural fidelity** â€“ Does the generator respect the causal structures of real data?

### Predictive tasks

* Classification & regression pipelines built on **scikitâ€‘learn**, with optional neuralâ€‘network backâ€‘ends.

## ðŸš€ Installation

We recommend managing dependencies with **conda**â€¯+â€¯**mamba**.

```bash
# 1ï¸âƒ£ Upgrade conda and activate the base env
a conda update -n base -c conda-forge conda
conda activate base

# 2ï¸âƒ£ Install the highâ€‘performance dependency resolver
conda install conda-libmamba-solver --yes
conda config --set solver libmamba
conda install -c conda-forge mamba --yes

# 3ï¸âƒ£ Create the project environment (â‰ˆ5â€‘10Â min)
mamba env create -f environment.yml
conda activate tabstruct

# 4ï¸âƒ£ (Optional) reâ€‘enable mamba in the new env
conda install conda-libmamba-solver --yes
conda config --set solver libmamba
conda install -c conda-forge mamba --yes

# 5ï¸âƒ£ Install patched thirdâ€‘party libraries
pip install -r private_repos/synthcity-private/requirements.txt
mamba install pytorch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 pytorch-cuda=12.1 -c pytorch -c nvidia
pip install dgl -f https://data.dgl.ai/wheels/torch-2.2/cu121/repo.html
pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.0+cu121.html
pip install -e private_repos/synthcity-private[goggle]
pip install -e private_repos/Camel
pip install -e private_repos/tabpfn
```

> **Headsâ€‘up:** Search the codebase for absolute paths and replace them with paths on your machine.

## ðŸ“Š Logging with W\&B

TabStruct logs every experiment to **WeightsÂ &Â Biases** (W\&B).  Use the default project or set your own credentials in `src/common/__init__.py`:

```python
WANDB_ENTITY  = "tabular-data-generation"
WANDB_PROJECT = "TabStruct"
```

## âœ… Quick sanity check

Run a toy classification job (Kâ€‘NN on the **Adult** dataset):

```bash
python -m src.experiment.run_experiment \
  --model knn \
  --save_model \
  --dataset adult \
  --test_size 0.2 \
  --valid_size 0.1 \
  --tags ENV-TEST
```

A successful run prints a series of **green** log lines like:

```text
[YYYYâ€‘MMâ€‘DD] Codebase: >>>>>>>>>> Launching create_data_module() <<<<<<<<<<<
â€¦
```

If you see those, congratulations â€“ your environment is ready! ðŸŽ‰

## ðŸ’¥ Example Workflows

### 1. Generate synthetic data

```bash
python -m src.experiment.run_experiment \
  --pipeline generation \
  --model smote \
  --generation_only \
  --dataset mfeat-fourier \
  --test_size 0.2 \
  --valid_size 0.1 \
  --tags SMOTE-generation
```

Template script: `scripts/template/generation/smote_generation.sh`.

---

### 2. Evaluate synthetic data

```bash
python -m src.experiment.run_experiment \
  --pipeline generation \
  --model smote \
  --eval_only \
  --dataset mfeat-fourier \
  --test_size 0.2 \
  --valid_size 0.1 \
  --generator_tags SMOTE-generation \
  --tags SMOTE-evaluation
```

Template script: `scripts/template/generation/smote_evaluation.sh`.

---

### 3. Launch a W\&B sweep (multiple data splits)

1. **Create the sweep config**
   Template: `scripts/template/sweep/baseline_generation_classification.yaml` (5 generators Ã— 3 datasets Ã— 10 splits).
2. **Initialise the sweep**

   ```bash
   wandb sweep scripts/template/sweep/baseline_generation_classification.yaml
   ```
   The command returns an agent ID (e.g. `tabular-data-generation/TabStruct/xxxxxxxx`).
3. **Launch agents**

   ```bash
   wandb agent AGENT_ID
   ```
   Each agent executes the full sweep defined above.

## ðŸ“€ Public Datasets Employed in TabStruct

* SCM datasets from bnlean

  * Classification

    ![image-20250515222136650](https://s2.loli.net/2025/05/16/eRDaPFAkiqwszxj.png)

  * Regression

    ![image-20250515222153930](https://s2.loli.net/2025/05/16/ivnoJ971cUzFyA3.png)

* Real-world datasets from OpenML and UCI

  * Classification

    ![image-20250515222104899](https://s2.loli.net/2025/05/16/dpzIo1fZqGQbBXy.png)

  * Regression

    ![image-20250515222120220](https://s2.loli.net/2025/05/16/JqVh3gFoxrKPck7.png)

